<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>New World Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="scrapyscrapy是为了爬取网站数据,提取结构性数据而编写的应用框架可以应用在包括数据挖掘,信息处理或存储历史数据等一系列的程序中. scrapy shell是一个交互scrapy终端，供你在未启动spider的情况下尝试及调试代码，可以作为正常的python终端，该终端是用来测试xpath或css表达式，查看他们的工作方式及从爬取的网页提取的数据。在编写你的spider时，该终端提供了交互">
<meta property="og:type" content="article">
<meta property="og:title" content="New World Blog">
<meta property="og:url" content="http://example.com/2024/07/12/scrapy%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="New World Blog">
<meta property="og:description" content="scrapyscrapy是为了爬取网站数据,提取结构性数据而编写的应用框架可以应用在包括数据挖掘,信息处理或存储历史数据等一系列的程序中. scrapy shell是一个交互scrapy终端，供你在未启动spider的情况下尝试及调试代码，可以作为正常的python终端，该终端是用来测试xpath或css表达式，查看他们的工作方式及从爬取的网页提取的数据。在编写你的spider时，该终端提供了交互">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/scrapyimg1.png">
<meta property="article:published_time" content="2024-07-11T16:19:00.694Z">
<meta property="article:modified_time" content="2024-03-26T12:32:38.898Z">
<meta property="article:author" content="YYT">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/scrapyimg1.png">
  
    <link rel="alternate" href="/atom.xml" title="New World Blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">New World Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">新世界博客</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-scrapy笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/07/12/scrapy%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2024-07-11T16:19:00.694Z" itemprop="datePublished">2024-07-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="scrapy"><a href="#scrapy" class="headerlink" title="scrapy"></a>scrapy</h1><p>scrapy是为了爬取网站数据,提取<strong>结构性数据</strong>而编写的<strong>应用框架</strong><br><br>可以应用在包括<strong>数据挖掘</strong>,<strong>信息处理</strong>或<strong>存储历史数据</strong>等一系列的程序中.</p>
<h2 id="scrapy-shell"><a href="#scrapy-shell" class="headerlink" title="scrapy shell"></a>scrapy shell</h2><p>是一个交互scrapy终端，供你在未启动spider的情况下尝试及调试代码，可以作为正常的python终端，该终端是用来测试xpath或css表达式，查看他们的工作方式及从爬取的网页提取的数据。在编写你的spider时，该终端提供了交互性测试你的表达式代码的功能，免去了每次修改后运行的麻烦。</p>
<h4 id="安装ipython（有高亮和自动补全）"><a href="#安装ipython（有高亮和自动补全）" class="headerlink" title="安装ipython（有高亮和自动补全）"></a>安装ipython（有高亮和自动补全）</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ipython</span><br></pre></td></tr></table></figure>

<h4 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h4><p>进入window终端直接输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell &lt;域名&gt;</span><br></pre></td></tr></table></figure>

<h2 id="scrapy项目"><a href="#scrapy项目" class="headerlink" title="scrapy项目"></a>scrapy项目</h2><p>不是直接在ide里面新建文件了,而是在终端输入命令</p>
<ol>
<li><p>创建项目</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;项目名称&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建爬虫文件(<code>../&lt;项目名称&gt;/&lt;项目名称&gt;/spiders</code>)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider &lt;爬虫文件名字&gt; &lt;要爬取的网页&gt;</span><br><span class="line"></span><br><span class="line">e.g.</span><br><span class="line">scrapy genspider baidu www.baidu.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行爬虫代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl &lt;爬虫的名字&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>&lt;爬虫的名字&gt;是要运行文件内的属性name的属性值</p>
</blockquote>
</li>
</ol>
<h2 id="scrapy项目结构"><a href="#scrapy项目结构" class="headerlink" title="scrapy项目结构"></a>scrapy项目结构</h2><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;项目名字</span><br><span class="line">    &gt;项目名字</span><br><span class="line">        &gt;spiders        <span class="params">#</span> 存储爬虫文件</span><br><span class="line">            init.py</span><br><span class="line">        init.py</span><br><span class="line">        items.py       <span class="params">#</span> 定义数据结构的地方 爬取的数据都包含哪些</span><br><span class="line">        middlewares.py <span class="params">#</span> 中间件 代理</span><br><span class="line">        pipelines.py   <span class="params">#</span> 管道 用来处理下载的数据</span><br><span class="line">        settings.py    <span class="params">#</span> 配置文件 robots协议 ua定义等</span><br></pre></td></tr></table></figure>
<blockquote>
<p>settings.py内有默认同意君子协议 <code>ROBOTSTXT.OBEY = True</code>, 取消后可以不遵循君子协议</p>
</blockquote>
<h2 id="response的属性和方法"><a href="#response的属性和方法" class="headerlink" title="response的属性和方法"></a>response的属性和方法</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">response.text           # 获取响应的字符串</span><br><span class="line">response.body           # 获取二进制数据</span><br><span class="line">response.url			# 获取网页域名</span><br><span class="line">response.status			# 获取网页状态码</span><br><span class="line">response.xpath          # 解析response的内容(不需要导入包)</span><br><span class="line">response.extract        # 提取seletor对象的data属性</span><br><span class="line">response.extract_first  # 提取seletor列表的第一个数据</span><br></pre></td></tr></table></figure>

<h2 id="scrapy工作原理"><a href="#scrapy工作原理" class="headerlink" title="scrapy工作原理"></a>scrapy工作原理</h2><ol>
<li><strong>引擎</strong>向<code>spiders</code>要<code>url</code></li>
<li><strong>引擎</strong>将要爬取的<code>url</code>给<strong>调度器</strong></li>
<li><strong>调度器</strong>会将<code>url</code>生成请求对象放入到指定仓库中</li>
<li>从队列中出队一个请求</li>
<li><strong>引擎</strong>将请求交给<strong>下载器</strong>进行处理</li>
<li><strong>下载器</strong>发送请求获取<code>互联网数据</code></li>
<li><strong>下载器</strong>将<code>数据</code>返回给<strong>引擎</strong></li>
<li><strong>引擎</strong>将<code>数据</code>发送给<code>spiders</code></li>
<li><code>spiders</code>通过<code>xpath</code>解析数据</li>
<li><code>spiders</code>将<code>数据</code>或者<code>url</code>传到<strong>引擎</strong></li>
<li><strong>引擎</strong>判断该数据是<code>数据</code>还是<code>url</code><ul>
<li><code>数据</code> - 交给<strong>管道</strong>处理</li>
<li><code>url</code> - 交给<strong>调度器</strong>循环上面操作</li>
</ul>
</li>
</ol>
<p><img src="/./img/scrapyimg1.png" alt="scrapy工作原理"></p>
<h2 id="crawlspider"><a href="#crawlspider" class="headerlink" title="crawlspider"></a>crawlspider</h2><p><strong>CrawlSpider</strong> 是 Scrapy 提供的一个通用 Spider。 在 Spider 里，我们可以指定一些<strong>爬取规则</strong>来实现页面的提取，这些爬取规则由一个专门的数据结构 <strong>Rule</strong> 表示。 Rule 里包含<strong>提取</strong>和<strong>跟进页面</strong>的配置， Spider 会根据 Rule来确定当前页面中的哪些链接需要继续爬取、哪些页面的爬取结果需要用哪个方法解析等。</p>
<h5 id="创建crawlspider"><a href="#创建crawlspider" class="headerlink" title="创建crawlspider"></a>创建crawlspider</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -t crawl &lt;爬虫文件名字&gt; &lt;域名&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>要比以往Spider爬虫建立时多了一个 <strong>-t crawl</strong> ；另外发现创建的爬虫文件中有一个<strong>rules</strong>属性，还有这个爬虫继承的类是<strong>CrawlSpider</strong>，这两点就是与前的Spider爬虫的区别。</p>
</blockquote>
<h5 id="链接提取器-制定规则"><a href="#链接提取器-制定规则" class="headerlink" title="链接提取器(制定规则)"></a>链接提取器(制定规则)</h5><p>链接提取器,在这里写规则提取指定链接</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"></span><br><span class="line">scrapy.linkextrators.LinkExtractor(</span><br><span class="line">	allow=&lt;xxx&gt;,			<span class="comment"># 正则表达式 提取符合正则的链接</span></span><br><span class="line">	deny=&lt;xxx&gt;,				<span class="comment"># 正则表达式 不提取符合正则的链接</span></span><br><span class="line">	allow_domains=&lt;xxx&gt;,	<span class="comment"># 允许的域名</span></span><br><span class="line">	deny_domains=&lt;xxx&gt;,		<span class="comment"># 不允许的域名</span></span><br><span class="line">	restrict_xpaths=&lt;xxx&gt;,	<span class="comment"># xpath 提取符合xpath规则的链接</span></span><br><span class="line">	restrict_css=&lt;xxx&gt;		<span class="comment"># 提取符合选择器的链接</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>e.g.</p>
<p><code>links1 = LinkExtractor(allow=r&#39;list_23_\d+.html&#39;)</code></p>
<p><code>links2 = LinkExtractor(restrict_css=&#39;.x&#39;)</code></p>
</blockquote>
<h5 id="提取链接"><a href="#提取链接" class="headerlink" title="提取链接"></a>提取链接</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;规则&gt;.extract_links(response)</span><br></pre></td></tr></table></figure>

<h2 id="scrapy-post请求"><a href="#scrapy-post请求" class="headerlink" title="scrapy post请求"></a>scrapy post请求</h2><p>在post请求中,start_urls和与之绑定的parse函数都没有用了</p>
<p>scrapy默认发送的是get请求，发送post请求时需要重写<code>start_requests(self)</code></p>
<p>使用Scrapy框架中的<code>FormRequest</code>类来发送POST请求</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">yield</span> scrapy.FormRequest(url=&lt;url&gt;, formdata=&lt;data&gt;, callback=<span class="variable language_">self</span>.&lt;函数&gt;)</span><br></pre></td></tr></table></figure>

<blockquote>
<p> 这段代码是使用Scrapy框架中的<code>FormRequest</code>类来发送POST请求，其中包括了要提交的表单数据<code>&lt;data&gt;</code>和目标URL <code>&lt;url&gt;</code>。一般来说，这段代码用于模拟用户在网页上填写表单并提交的行为。一旦服务器响应了这个请求，它会调用<code>&lt;函数&gt;</code>方法来处理响应并提取数据。</p>
</blockquote>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>在settings.py里面设置</p>
<ul>
<li><pre><code class="python">LOG_LEVEL = &#39;&lt;日志级别&gt;&#39;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  日志级别:</span><br><span class="line"></span><br><span class="line">  - `CRITICAL` : 严重错误</span><br><span class="line">  - `ERROR` : 一般错误</span><br><span class="line">  - `WARNING` : 警告</span><br><span class="line">  - `INFO` : 一般信息</span><br><span class="line">  - `DEBUG` : 调试信息(默认)</span><br><span class="line"></span><br><span class="line">  &gt; 运行文件是会显示当前等级及以上的日志</span><br><span class="line"></span><br><span class="line">- ```python</span><br><span class="line">  LOG_FILE = &#x27;&lt;文件名&gt;.log&#x27;</span><br></pre></td></tr></table></figure>

&gt; 把日志另外保存在`&lt;文件名&gt;.log`文件内,不显示在屏幕
</code></pre>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/07/12/scrapy%E7%AC%94%E8%AE%B0/" data-id="clyhh54c400046cuh3tdwf91t" data-title="" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/07/12/shell/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2024/07/12/python%E4%B8%8EMySQL%E7%9A%84%E8%BF%9E%E6%8E%A5/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">七月 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/07/12/%E5%9C%A8%E6%96%87%E4%BB%B6%E5%A4%B9%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0%E2%80%9COpen%20Folder%20as%20XXX%E2%80%9D/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/07/12/%E9%9D%99%E6%80%81%E6%88%90%E5%91%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/07/12/%E8%A7%A3%E5%86%B3%EF%BC%9Avue3%E4%BD%BF%E7%94%A8vite%E6%9E%84%E5%BB%BA%E7%9A%84%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85%E5%90%8E%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80index.html%E6%96%87%E4%BB%B6/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/07/12/%E9%9B%86%E6%88%90%E6%94%AF%E4%BB%98%E5%AE%9D/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/07/12/vue3/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 YYT<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>